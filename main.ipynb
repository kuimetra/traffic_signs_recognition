{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import MaxPool2D, Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib.image import imread\n",
    "from keras.utils import to_categorical\n",
    "from PIL import Image, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import visualkeras\n",
    "import random\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Meta.csv\")\n",
    "num_classes = df.shape[0]\n",
    "meta_path, classes = df[\"Path\"], df[\"ClassLabel\"]\n",
    "font = ImageFont.truetype(\"arial.ttf\", 15)\n",
    "seed = 123"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_path = \"data/Train/\"\n",
    "test_path = \"data/Test/\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Traffic signs visualization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(7, 7, figsize=(10, 10))\n",
    "\n",
    "for i, path in enumerate(meta_path):\n",
    "    img = plt.imread(\"data/\" + path)\n",
    "\n",
    "    row, col = i // 7, i % 7\n",
    "\n",
    "    ax[row, col].imshow(img)\n",
    "    ax[row, col].axis(\"off\")\n",
    "    ax[row, col].set_title(f\"({i}) {classes[i]}\", fontdict={\"fontsize\": 7}, y=-0.3)\n",
    "\n",
    "fig.suptitle(\"Traffic signs\", fontsize=15)\n",
    "fig.subplots_adjust(top=1.5)\n",
    "fig.tight_layout(pad=0.75)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plotting the distribution of images among different classes in the training set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folders = os.listdir(train_path)\n",
    "\n",
    "label_amount, class_num = [], []\n",
    "\n",
    "for label in folders:\n",
    "    train_files = os.listdir(train_path + \"/\" + label)\n",
    "    label_amount.append(len(train_files))\n",
    "    class_num.append(label)\n",
    "\n",
    "cmap = plt.get_cmap(\"BuPu\")\n",
    "normalize = plt.Normalize(vmin=min(label_amount), vmax=max(label_amount))\n",
    "colors = [cmap(normalize(value)) for value in label_amount]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(class_num, label_amount, color=colors)\n",
    "plt.xticks(class_num, rotation=\"vertical\")\n",
    "plt.title(\"Distribution of images among different classes\", fontsize=15)\n",
    "plt.xlabel(\"Class ID\")\n",
    "plt.ylabel(\"amount\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Displaying random selection of test images with dimensions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images_path = os.listdir(test_path)\n",
    "\n",
    "fig, ax = plt.subplots(5, 5, figsize=(10, 10))\n",
    "\n",
    "for i in range(25):\n",
    "    rand_img = imread(test_path + \"/\" + random.choice(images_path))\n",
    "\n",
    "    row, col = i // 5, i % 5\n",
    "\n",
    "    ax[row, col].imshow(rand_img)\n",
    "    ax[row, col].set_xlabel(rand_img.shape[1], fontsize=10)\n",
    "    ax[row, col].set_ylabel(rand_img.shape[0], fontsize=10)\n",
    "\n",
    "fig.suptitle(\"Random selection of test images\", fontsize=15)\n",
    "fig.subplots_adjust(top=1.5)\n",
    "fig.tight_layout(pad=0.8)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images, labels = [], []\n",
    "\n",
    "for label in range(num_classes):\n",
    "    path = os.path.join(train_path, str(label))\n",
    "    imgs = os.listdir(path)\n",
    "    for img in imgs:\n",
    "        image = Image.open(path + \"/\" + img)\n",
    "        image = image.resize((30, 30))\n",
    "        image = np.array(image)\n",
    "\n",
    "        images.append(image)\n",
    "        labels.append(label)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images, labels = np.array(images), np.array(labels)\n",
    "\n",
    "print(images.shape, labels.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data splitting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_rem, y_train, y_rem = train_test_split(images, labels, test_size=0.3, shuffle=True, random_state=seed)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_rem, y_rem, test_size=0.5, shuffle=True, random_state=seed)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    return cv2.normalize(img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def equalize(img):\n",
    "    return cv2.equalizeHist(img)\n",
    "\n",
    "\n",
    "def preprocess(img):\n",
    "    img = normalize(img)\n",
    "    img = grayscale(img)\n",
    "    img = equalize(img)\n",
    "    img = img / 255\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Preprocessing steps for sample image from training dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(8, 8))\n",
    "\n",
    "img_sample = X_train[16]\n",
    "ax[0].imshow(img_sample)\n",
    "\n",
    "img_sample = normalize(img_sample)\n",
    "ax[1].imshow(img_sample)\n",
    "\n",
    "img_sample = grayscale(img_sample)\n",
    "ax[2].imshow(img_sample)\n",
    "\n",
    "img_sample = equalize(img_sample)\n",
    "ax[3].imshow(img_sample)\n",
    "\n",
    "ax[0].set_title(\"X_train[0]\")\n",
    "ax[1].set_title(\"normalize\")\n",
    "ax[2].set_title(\"grayscale\")\n",
    "ax[3].set_title(\"equalize\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = np.array(list(map(preprocess, X_train)))\n",
    "X_test = np.array(list(map(preprocess, X_test)))\n",
    "X_val = np.array(list(map(preprocess, X_val)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "X_val = np.expand_dims(X_val, axis=-1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data Augmentation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=10,\n",
    "                             width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1,\n",
    "                             zoom_range=0.1,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode=\"nearest\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_val = to_categorical(y_val, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model Initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_shape = (30, 30, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LeNet5_model = Sequential([\n",
    "    Conv2D(filters=6, kernel_size=(5, 5), activation=\"relu\", input_shape=input_shape),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\"),\n",
    "    MaxPool2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(units=120, activation=\"relu\"),\n",
    "    Dense(units=84, activation=\"relu\"),\n",
    "    Dense(units=num_classes, activation=\"softmax\")\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AlexNet_model = Sequential([\n",
    "    # 1st Convolutional Layer\n",
    "    Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), padding=\"same\", input_shape=input_shape),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "\n",
    "    # 2nd Convolutional Layer\n",
    "    Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), padding=\"same\"),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "\n",
    "    # 3rd Convolutional Layer\n",
    "    Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding=\"same\"),\n",
    "    Activation(\"relu\"),\n",
    "\n",
    "    # 4th Convolutional Layer\n",
    "    Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), padding=\"same\"),\n",
    "    Activation(\"relu\"),\n",
    "\n",
    "    # 5th Convolutional Layer\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding=\"same\"),\n",
    "    Activation(\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "\n",
    "    # Flatten the layers\n",
    "    Flatten(),\n",
    "\n",
    "    # 1st Dense Layer\n",
    "    Dense(4096, input_shape=(30 * 30 * 1,)),\n",
    "    Activation(\"relu\"),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    # 2nd Dense Layer\n",
    "    Dense(4096),\n",
    "    Activation(\"relu\"),\n",
    "    Dropout(0.4),\n",
    "\n",
    "    # Output Layer\n",
    "    Dense(num_classes),\n",
    "    Activation(\"softmax\")\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "VGG16_model = Sequential([\n",
    "    # Block 1\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\", input_shape=input_shape),\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    # Block 2\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    # Block 3\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    Conv2D(filters=256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "    # Block 4\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "\n",
    "    # Block 5\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    Conv2D(filters=512, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
    "    MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"same\"),\n",
    "\n",
    "    # Fully connected layers\n",
    "    Flatten(),\n",
    "    Dense(units=4096, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=4096, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(units=num_classes, activation=\"softmax\")\n",
    "])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualization of model architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualkeras.layered_view(LeNet5_model, legend=True, font=font, draw_volume=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualkeras.layered_view(AlexNet_model, legend=True, font=font, draw_volume=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "visualkeras.layered_view(VGG16_model, legend=True, font=font, draw_volume=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, X_val, y_val, lr, momentum, batch_size, num_epochs):\n",
    "    # optimizer = SGD(learning_rate=lr, momentum=momentum)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(datagen.flow(X_train, y_train, batch_size=batch_size), epochs=num_epochs,\n",
    "                        validation_data=(X_val, y_val))\n",
    "\n",
    "    return history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"Test Accuracy: {round(test_acc * 100, 3)}%\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LeNet5_history = train_model(LeNet5_model, X_train, y_train, X_val, y_val,\n",
    "                             lr=1e-4, momentum=0.9, batch_size=32, num_epochs=30)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate_model(LeNet5_model, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AlexNet_history = train_model(AlexNet_model, X_train, y_train, X_val, y_val,\n",
    "                              lr=1e-4, momentum=0.9, batch_size=32, num_epochs=15)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate_model(AlexNet_model, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "VGG16_history = train_model(VGG16_model, X_train, y_train, X_val, y_val,\n",
    "                            lr=1e-4, momentum=0.9, batch_size=32, num_epochs=15)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "evaluate_model(VGG16_model, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Plotting training and validation accuracy of each model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_history(history, model_name):\n",
    "    train_acc = history.history[\"accuracy\"]\n",
    "    val_acc = history.history[\"val_accuracy\"]\n",
    "    epochs = range(1, len(train_acc) + 1)\n",
    "    plt.plot(epochs, train_acc, label=\"Training accuracy\")\n",
    "    plt.plot(epochs, val_acc, label=\"Validation accuracy\")\n",
    "    plt.title(f\"Training and validation accuracy for {model_name}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_history(LeNet5_history, \"LeNet-5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_history(AlexNet_history, \"AlexNet\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_history(VGG16_history, \"VGG16\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/Test.csv\")\n",
    "\n",
    "test_labels, test_imgs_path = test_data[\"ClassId\"].values, test_data[\"Path\"].values\n",
    "test_imgs = []\n",
    "\n",
    "for img in test_imgs_path:\n",
    "    image = Image.open(\"data/\" + img)\n",
    "    image = image.resize((30, 30))\n",
    "    test_imgs.append(np.array(image))\n",
    "\n",
    "test_imgs = np.array(test_imgs) / 255"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_pred_LeNet5 = np.argmax(LeNet5_model.predict(test_imgs), axis=1)\n",
    "test_pred_AlexNet = np.argmax(AlexNet_model.predict(test_imgs), axis=1)\n",
    "test_pred_VGG16 = np.argmax(VGG16_model.predict(test_imgs), axis=1)\n",
    "\n",
    "#Accuracy with the test data\n",
    "print(accuracy_score(test_labels, test_pred_LeNet5))\n",
    "print(accuracy_score(test_labels, test_pred_AlexNet))\n",
    "print(accuracy_score(test_labels, test_pred_VGG16))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Saving machine learning models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LeNet5_model.save(\"traffic_classifier_LeNet5.h5\")\n",
    "AlexNet_model.save(\"traffic_classifier_AlexNet.h5\")\n",
    "VGG16_model.save(\"traffic_classifier_VGG16.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
